# app.py
import streamlit as st
from PIL import Image
import torch
from transformers import (
    BlipProcessor, 
    BlipForQuestionAnswering,
    MarianTokenizer,
    MarianMTModel
)
import logging
import time
import gc
import psutil
import os

# Setup logging
logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)

# Egyptian Medical Terminology Dictionary
EGYPTIAN_MEDICAL_TERMS = {
    "chest x-ray": "Ø£Ø´Ø¹Ø© Ø¹Ù„Ù‰ Ø§Ù„ØµØ¯Ø±",
    "x-ray": "Ø£Ø´Ø¹Ø© Ø³ÙŠÙ†ÙŠØ©", 
    "ct scan": "Ø£Ø´Ø¹Ø© Ù…Ù‚Ø·Ø¹ÙŠØ©",
    "mri": "Ø±Ù†ÙŠÙ† Ù…ØºÙ†Ø§Ø·ÙŠØ³ÙŠ",
    "ultrasound": "Ø³ÙˆÙ†Ø§Ø±",
    "normal": "Ø·Ø¨ÙŠØ¹ÙŠ",
    "abnormal": "Ù…Ø´ Ø·Ø¨ÙŠØ¹ÙŠ",
    "healthy": "Ø³Ù„ÙŠÙ…",
    "no abnormality detected": "Ù…Ø§ÙÙŠØ´ Ø­Ø§Ø¬Ø© ØºÙ„Ø·",
    "no issues found": "Ù…Ø§ÙÙŠØ´ Ù…Ø´Ø§ÙƒÙ„",
    "everything looks fine": "ÙƒÙ„Ù‡ ØªÙ…Ø§Ù…",
    "consultation needed": "Ù…Ø­ØªØ§Ø¬ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø¯ÙƒØªÙˆØ±"
}

# Enhanced Egyptian Arabic responses
EGYPTIAN_RESPONSES = {
    "general_health": ["Ø§Ù„ØµØ­Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ØªØ¨Ø¯Ùˆ ÙƒÙˆÙŠØ³Ø© Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡", "Ø¨Ø§Ù„Ù†Ø¸Ø± Ù„Ù„ØµÙˆØ±Ø©ØŒ Ø§Ù„ÙˆØ¶Ø¹ ÙŠØ¨Ø¯Ùˆ Ø·Ø¨ÙŠØ¹ÙŠ"],
    "chest_normal": ["Ø§Ù„ØµØ¯Ø± Ø³Ù„ÙŠÙ… ÙˆØ§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡", "Ø§Ù„Ø±Ø¦ØªÙŠÙ† Ø´ØºØ§Ù„ÙŠÙ† ÙƒÙˆÙŠØ³"],
    "needs_consultation": ["Ø£Ù†ØµØ­Ùƒ ØªØ³ØªØ´ÙŠØ± Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ", "Ø§Ù„Ø£ÙØ¶Ù„ ØªØ¹Ù…Ù„ ÙƒØ´Ù Ø¹Ù†Ø¯ Ø¯ÙƒØªÙˆØ±"],
    "bone_health": ["Ø§Ù„Ø¹Ø¶Ø§Ù… ØªØ¨Ø¯Ùˆ Ø³Ù„ÙŠÙ…Ø©", "Ù…Ø§ÙÙŠØ´ ÙƒØ³ÙˆØ± ÙˆØ§Ø¶Ø­Ø©"]
}

@st.cache_resource(show_spinner=False)
def load_models():
    """Load BLIP and translation models with enhanced error handling"""
    try:
        # Load BLIP processor and model
        processor = BlipProcessor.from_pretrained("Salesforce/blip-vqa-base")
        model = BlipForQuestionAnswering.from_pretrained(
            "Salesforce/blip-vqa-base",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            device_map="auto" if torch.cuda.is_available() else "cpu"
        )
        
        # Load translation models
        ar_en_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-ar-en")
        ar_en_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-ar-en")
        en_ar_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-ar")
        en_ar_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-ar")
        logger.info("All models loaded successfully")
        return processor, model, ar_en_tokenizer, ar_en_model, en_ar_tokenizer, en_ar_model
    except Exception as e:
        logger.exception("Critical model loading error")
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {str(e)}")
        st.stop()

def detect_language(text):
    """Detect if text is Arabic or English"""
    arabic_chars = sum(1 for c in text if '\u0600' <= c <= '\u06FF')
    return 'ar' if arabic_chars > len(text) * 0.3 else 'en'

def translate_medical_response(answer_en, en_ar_tokenizer, en_ar_model):
    """Enhanced medical translation with Egyptian terminology"""
    answer_lower = answer_en.lower().strip()
    # First check for exact matches in Egyptian medical terms
    if answer_lower in EGYPTIAN_MEDICAL_TERMS:
        return EGYPTIAN_MEDICAL_TERMS[answer_lower]
    # Fallback to machine translation
    try:
        inputs = en_ar_tokenizer(answer_en, return_tensors="pt", padding=True, truncation=True, max_length=512)
        outputs = en_ar_model.generate(**inputs, max_length=512, num_beams=2, early_stopping=True)
        return en_ar_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
    except Exception as e:
        logger.error(f"Translation error: {e}")
        return answer_en

def resize_image(image, max_size=512):
    """Resize image to reduce memory usage"""
    if max(image.size) > max_size:
        image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
    return image

def process_medical_query(image, question, processor, model, ar_en_tokenizer, ar_en_model, en_ar_tokenizer, en_ar_model):
    """Process medical image and question with enhanced Egyptian Arabic support"""
    try:
        # Detect question language
        detected_lang = detect_language(question)
        # Prepare questions in both languages
        if detected_lang == 'ar':
            question_ar = question.strip()
            question_en = translate_ar_to_en(question_ar, ar_en_tokenizer, ar_en_model)
        else:
            question_en = question.strip()
            question_ar = translate_en_to_ar(question_en, en_ar_tokenizer, en_ar_model)
        # Resize image to save memory
        image_resized = resize_image(image)
        # Process with BLIP model
        device = "cuda" if torch.cuda.is_available() else "cpu"
        inputs = processor(image_resized, question_en, return_tensors="pt").to(device)
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=100,
                num_beams=3,
                early_stopping=True,
                do_sample=False
            )
        # Decode answer
        answer_en = processor.decode(outputs[0], skip_special_tokens=True).strip()
        answer_ar = translate_medical_response(answer_en, en_ar_tokenizer, en_ar_model)
        # Memory cleanup
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        return question_ar, question_en, answer_ar, answer_en
    except Exception as e:
        logger.exception("Medical query processing failed")
        error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"
        return error_msg, f"Processing error: {str(e)}", error_msg, f"Processing error: {str(e)}"

def get_memory_usage():
    """Get current memory usage"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # MB

def main():
    st.set_page_config(
        page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØµØ­Ø© Ø§Ù„Ù…ØµØ±ÙŠ - Egyptian Health Assistant",
        layout="wide",
        page_icon="ğŸ‡ªğŸ‡¬",
        initial_sidebar_state="expanded"
    )

    # Header with Egyptian theme
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ‡ªğŸ‡¬ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØµØ­Ø© Ø§Ù„Ù…ØµØ±ÙŠ ğŸ‡ªğŸ‡¬</h1>
        <h2>Egyptian Medical AI Assistant</h2>
        <p>Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ø·Ø¨ÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©</p>
        <p>AI-powered medical diagnosis in Egyptian Arabic</p>
    </div>
    """, unsafe_allow_html=True)

    # Load models with progress indicator
    with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø·Ø¨ÙŠØ©... Loading medical AI models..."):
        try:
            processor, model, ar_en_tokenizer, ar_en_model, en_ar_tokenizer, en_ar_model = load_models()
            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­! Models loaded successfully!")
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {str(e)}")
            st.stop()

    # Main interface
    col1, col2 = st.columns([1, 1], gap="large")
    with col1:
        st.markdown("""
        <div class="card">
            <h3 style="text-align: center; margin-bottom: 1.5rem;">
                ğŸ“· Ø§Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·Ø¨ÙŠØ©<br>Upload Medical Image
            </h3>
        </div>
        """, unsafe_allow_html=True)
        uploaded_file = st.file_uploader(
            "Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø·Ø¨ÙŠØ© / Choose medical image", 
            type=["jpg", "png", "jpeg", "bmp", "tiff"],
            help="Ø§Ø±ÙØ¹ Ø£Ø´Ø¹Ø© Ø£Ùˆ ØµÙˆØ± Ø·Ø¨ÙŠØ© Ù„Ù„ØªØ´Ø®ÙŠØµ / Upload X-rays or medical images for diagnosis"
        )
        if uploaded_file:
            try:
                image = Image.open(uploaded_file).convert("RGB")
                st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© / Uploaded Image", use_container_width=True)
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")

    with col2:
        st.markdown("""
        <div class="card">
            <h3 style="text-align: center; margin-bottom: 1.5rem;">
                ğŸ’¬ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ø·Ø¨ÙŠ<br>Ask Your Medical Question
            </h3>
        </div>
        """, unsafe_allow_html=True)
        st.info("ğŸ’¡ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© / Write your question in Arabic or English")
        question = st.text_area(
            "Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ø·Ø¨ÙŠ / Your medical question:",
            placeholder="Ù…Ø«Ø§Ù„: Ø¥ÙŠÙ‡ Ø§Ù„Ù„ÙŠ Ø¨Ø§ÙŠÙ† ÙÙŠ Ø§Ù„Ø£Ø´Ø¹Ø© Ø¯ÙŠØŸ\nExample: What do you see in this X-ray?",
            height=120,
            help="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­ Ø¹Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·Ø¨ÙŠØ© / Write your question clearly about the medical image"
        )
        # Analyze button
        if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø·Ø¨ÙŠ / Medical Analysis", use_container_width=True):
            if not uploaded_file or not question.strip():
                st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ ØµÙˆØ±Ø© ÙˆÙƒØªØ§Ø¨Ø© Ø³Ø¤Ø§Ù„ / Please upload an image and enter a question")
            else:
                with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ø¨ÙŠ... Analyzing medical image..."):
                    try:
                        start_time = time.time()
                        image_pil = Image.open(uploaded_file).convert("RGB")
                        q_ar, q_en, a_ar, a_en = process_medical_query(
                            image_pil, question, processor, model,
                            ar_en_tokenizer, ar_en_model, en_ar_tokenizer, en_ar_model
                        )
                        processing_time = time.time() - start_time

                        # Display results
                        st.markdown("""
                        <div class="result-container">
                            <h2 style="text-align: center; margin-bottom: 2rem;">
                                ğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ø¨ÙŠ / Medical Analysis Results
                            </h2>
                        </div>
                        """, unsafe_allow_html=True)
                        res_col1, res_col2 = st.columns(2)
                        with res_col1:
                            st.markdown("### ğŸ‡ªğŸ‡¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© / Arabic")
                            st.markdown(f'<div class="arabic-text">{q_ar}</div>', unsafe_allow_html=True)
                            st.markdown(f'<div class="arabic-text" style="background: #e8f5e8; padding: 1rem; border-radius: 10px; color: #2d5a2d;">{a_ar}</div>', unsafe_allow_html=True)
                        with res_col2:
                            st.markdown("### ğŸ‡ºğŸ‡¸ English")
                            st.markdown(f'<div class="english-text">{q_en}</div>', unsafe_allow_html=True)
                            st.markdown(f'<div class="english-text" style="background: #e8f5e8; padding: 1rem; border-radius: 10px; color: #2d5a2d;">{a_en}</div>', unsafe_allow_html=True)
                        memory_usage = get_memory_usage()
                        st.markdown(f"""
                        <div class="memory-info">
                            â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_time:.2f} Ø«Ø§Ù†ÙŠØ© / Processing time: {processing_time:.2f} seconds<br>
                            ğŸ’¾ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {memory_usage:.1f} MB / Memory usage: {memory_usage:.1f} MB
                        </div>
                        """, unsafe_allow_html=True)
                    except Exception as e:
                        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}")

    # Footer with medical disclaimer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; padding: 2rem; background: #f8f9fa; border-radius: 15px; margin-top: 2rem;">
        <h4>ğŸ¥ Ø¥Ø®Ù„Ø§Ø¡ Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© Ø·Ø¨ÙŠØ© / Medical Disclaimer</h4>
        <p><strong>Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ ÙŠÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£ÙˆÙ„ÙŠØ© ÙÙ‚Ø· ÙˆÙ„Ø§ ÙŠØ­Ù„ Ù…Ø­Ù„ Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ®ØµØµØ©</strong></p>
        <p><strong>This AI assistant provides preliminary information only and does not replace professional medical consultation</strong></p>
        <p>ğŸ”¬ Ù…Ø¯Ø¹ÙˆÙ… Ø¨ØªÙ‚Ù†ÙŠØ© BLIP Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø·Ø¨ÙŠ / Powered by BLIP Medical AI Technology</p>
        <p>ğŸ‡ªğŸ‡¬ ØµÙÙ…Ù… Ø®ØµÙŠØµØ§Ù‹ Ù„Ù„Ù…Ø¬ØªÙ…Ø¹ Ø§Ù„Ù…ØµØ±ÙŠ / Designed specifically for the Egyptian community</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
