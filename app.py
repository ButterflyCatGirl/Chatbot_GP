import streamlit as st
from PIL import Image
import torch
from transformers import (
    BlipProcessor, 
    BlipForQuestionAnswering,
    MarianTokenizer,
    MarianMTModel
)
import logging
import time
import gc
#import psutil
import os

# Setup logging
logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)

# Egyptian Medical Terminology Dictionary
EGYPTIAN_MEDICAL_TERMS = {
    # Basic medical terms
    "chest x-ray": "Ø£Ø´Ø¹Ø© Ø¹Ù„Ù‰ Ø§Ù„ØµØ¯Ø±",
    "x-ray": "Ø£Ø´Ø¹Ø© Ø³ÙŠÙ†ÙŠØ©", 
    "ct scan": "Ø£Ø´Ø¹Ø© Ù…Ù‚Ø·Ø¹ÙŠØ©",
    "mri": "Ø±Ù†ÙŠÙ† Ù…ØºÙ†Ø§Ø·ÙŠØ³ÙŠ",
    "ultrasound": "Ø³ÙˆÙ†Ø§Ø±",
    "normal": "Ø·Ø¨ÙŠØ¹ÙŠ",
    "abnormal": "Ù…Ø´ Ø·Ø¨ÙŠØ¹ÙŠ",
    "healthy": "Ø³Ù„ÙŠÙ…",
    "no abnormality detected": "Ù…Ø§ÙÙŠØ´ Ø­Ø§Ø¬Ø© ØºÙ„Ø·",
    "no issues found": "Ù…Ø§ÙÙŠØ´ Ù…Ø´Ø§ÙƒÙ„",
    
    # Body parts - Egyptian dialect
    "brain": "Ø§Ù„Ù…Ø®",
    "heart": "Ø§Ù„Ù‚Ù„Ø¨", 
    "liver": "Ø§Ù„ÙƒØ¨Ø¯",
    "kidney": "Ø§Ù„ÙƒÙ„Ù‰",
    "lungs": "Ø§Ù„Ø±Ø¦ØªÙŠÙ†",
    "left lung": "Ø§Ù„Ø±Ø¦Ø© Ø§Ù„Ø´Ù…Ø§Ù„",
    "right lung": "Ø§Ù„Ø±Ø¦Ø© Ø§Ù„ÙŠÙ…ÙŠÙ†",
    "bone": "Ø§Ù„Ø¹Ø¶Ù…",
    "bones": "Ø§Ù„Ø¹Ø¶Ø§Ù…",
    "spine": "Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ",
    "chest": "Ø§Ù„ØµØ¯Ø±",
    "abdomen": "Ø§Ù„Ø¨Ø·Ù†",
    "stomach": "Ø§Ù„Ù…Ø¹Ø¯Ø©",
    
    # Common conditions - Egyptian style
    "pneumonia": "Ø§Ù„ØªÙ‡Ø§Ø¨ Ø±Ø¦ÙˆÙŠ",
    "infection": "Ø¹Ø¯ÙˆÙ‰",
    "fracture": "ÙƒØ³Ø±",
    "broken": "Ù…ÙƒØ³ÙˆØ±",
    "tumor": "ÙˆØ±Ù…",
    "cancer": "Ø³Ø±Ø·Ø§Ù†",
    "inflammation": "Ø§Ù„ØªÙ‡Ø§Ø¨",
    "swelling": "ÙˆØ±Ù…",
    "pain": "ÙˆØ¬Ø¹",
    "ache": "Ø£Ù„Ù…",
    
    # Blood vessels
    "blood vessel": "ÙˆØ¹Ø§Ø¡ Ø¯Ù…ÙˆÙŠ",
    "artery": "Ø´Ø±ÙŠØ§Ù†", 
    "vein": "ÙˆØ±ÙŠØ¯",
    "blood": "Ø¯Ù…",
    
    # Diagnosis terms
    "benign": "Ø­Ù…ÙŠØ¯",
    "malignant": "Ø®Ø¨ÙŠØ«",
    "chronic": "Ù…Ø²Ù…Ù†",
    "acute": "Ø­Ø§Ø¯",
    
    # Egyptian conversational responses
    "everything looks fine": "ÙƒÙ„Ù‡ ØªÙ…Ø§Ù…",
    "looks good": "ÙŠØ¨Ø¯Ùˆ ÙƒÙˆÙŠØ³",
    "appears normal": "ÙŠØ¨Ø¯Ùˆ Ø·Ø¨ÙŠØ¹ÙŠ",
    "no problems": "Ù…Ø§ÙÙŠØ´ Ù…Ø´Ø§ÙƒÙ„",
    "consultation needed": "Ù…Ø­ØªØ§Ø¬ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø¯ÙƒØªÙˆØ±",
    "see a doctor": "Ø±ÙˆØ­ Ù„Ù„Ø¯ÙƒØªÙˆØ±",
    "further examination": "ÙØ­Øµ Ø£ÙƒØªØ±"
}

# Enhanced Egyptian Arabic responses for common medical queries
EGYPTIAN_RESPONSES = {
    "general_health": [
        "Ø§Ù„ØµØ­Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ØªØ¨Ø¯Ùˆ ÙƒÙˆÙŠØ³Ø© Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡",
        "Ø¨Ø§Ù„Ù†Ø¸Ø± Ù„Ù„ØµÙˆØ±Ø©ØŒ Ø§Ù„ÙˆØ¶Ø¹ ÙŠØ¨Ø¯Ùˆ Ø·Ø¨ÙŠØ¹ÙŠ",
        "Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø§Ù„Ø£Ù…ÙˆØ± ØªØ¨Ø¯Ùˆ ØªÙ…Ø§Ù…"
    ],
    "chest_normal": [
        "Ø§Ù„ØµØ¯Ø± Ø³Ù„ÙŠÙ… ÙˆØ§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡", 
        "Ø§Ù„Ø±Ø¦ØªÙŠÙ† Ø´ØºØ§Ù„ÙŠÙ† ÙƒÙˆÙŠØ³",
        "Ù…Ø§ÙÙŠØ´ Ø­Ø§Ø¬Ø© ØªÙ‚Ù„Ù‚ ÙÙŠ Ø§Ù„ØµØ¯Ø±"
    ],
    "needs_consultation": [
        "Ø£Ù†ØµØ­Ùƒ ØªØ³ØªØ´ÙŠØ± Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ",
        "Ø§Ù„Ø£ÙØ¶Ù„ ØªØ¹Ù…Ù„ ÙƒØ´Ù Ø¹Ù†Ø¯ Ø¯ÙƒØªÙˆØ±",
        "Ù…Ø­ØªØ§Ø¬ Ø±Ø£ÙŠ Ø·Ø¨ÙŠ Ù…ØªØ®ØµØµ"
    ],
    "bone_health": [
        "Ø§Ù„Ø¹Ø¶Ø§Ù… ØªØ¨Ø¯Ùˆ Ø³Ù„ÙŠÙ…Ø©", 
        "Ù…Ø§ÙÙŠØ´ ÙƒØ³ÙˆØ± ÙˆØ§Ø¶Ø­Ø©",
        "Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¹Ø¸Ù…ÙŠ Ø³Ù„ÙŠÙ…"
    ]
}

@st.cache_resource(show_spinner=False)
def load_models():
    """Load BLIP and translation models with enhanced error handling"""
    try:
        # Load BLIP processor and model
        processor = BlipProcessor.from_pretrained("Salesforce/blip-vqa-base")
        
        # Try custom model first, fallback to base model
        try:
            model = BlipForQuestionAnswering.from_pretrained(
                "ButterflyCatGirl/Blip-Streamlit-chatbot",
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else "cpu"
            )
            logger.info("Custom BLIP model loaded successfully")
        except Exception as e:
            logger.warning(f"Custom model failed, using base model: {e}")
            model = BlipForQuestionAnswering.from_pretrained(
                "Salesforce/blip-vqa-base",
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else "cpu"
            )
            logger.info("Base BLIP model loaded successfully")
        
        # Load translation models
        ar_en_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-ar-en")
        ar_en_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-ar-en")
        en_ar_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-ar")
        en_ar_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-ar")
        
        logger.info("All models loaded successfully")
        return processor, model, ar_en_tokenizer, ar_en_model, en_ar_tokenizer, en_ar_model
        
    except Exception as e:
        logger.exception("Critical model loading error")
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {str(e)}")
        st.error(f"Model loading error: {str(e)}")
        st.stop()

def detect_language(text):
    """Detect if text is Arabic or English"""
    arabic_chars = sum(1 for c in text if '\u0600' <= c <= '\u06FF')
    return 'ar' if arabic_chars > len(text) * 0.3 else 'en'

def translate_ar_to_en(text, tokenizer, model):
    """Translate Arabic to English with error handling"""
    try:
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        outputs = model.generate(**inputs, max_length=512, num_beams=2, early_stopping=True)
        translated = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
        return translated if translated else text
    except Exception as e:
        logger.error(f"Arabic to English translation error: {e}")
        return text

def translate_en_to_ar(text, tokenizer, model):
    """Translate English to Arabic with error handling"""
    try:
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        outputs = model.generate(**inputs, max_length=512, num_beams=2, early_stopping=True)
        translated = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
        return translated if translated else text
    except Exception as e:
        logger.error(f"English to Arabic translation error: {e}")
        return text

def translate_medical_response(answer_en, en_ar_tokenizer, en_ar_model):
    """Enhanced medical translation with Egyptian terminology"""
    answer_lower = answer_en.lower().strip()
    
    # First check for exact matches in Egyptian medical terms
    if answer_lower in EGYPTIAN_MEDICAL_TERMS:
        return EGYPTIAN_MEDICAL_TERMS[answer_lower]
    
    # Check for partial matches
    for english_term, egyptian_term in EGYPTIAN_MEDICAL_TERMS.items():
        if english_term in answer_lower:
            return egyptian_term
    
    # Check for contextual responses
    if any(word in answer_lower for word in ["normal", "fine", "healthy", "good"]):
        if "chest" in answer_lower or "lung" in answer_lower:
            return EGYPTIAN_RESPONSES["chest_normal"][0]
        elif "bone" in answer_lower:
            return EGYPTIAN_RESPONSES["bone_health"][0]
        else:
            return EGYPTIAN_RESPONSES["general_health"][0]
    
    if any(word in answer_lower for word in ["consult", "doctor", "specialist", "examination"]):
        return EGYPTIAN_RESPONSES["needs_consultation"][0]
    
    # Fallback to machine translation
    return translate_en_to_ar(answer_en, en_ar_tokenizer, en_ar_model)

def resize_image(image, max_size=800):
    """Resize image to reduce memory usage"""
    if max(image.size) > max_size:
        image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
    return image

def process_medical_query(image, question, processor, model, ar_en_tokenizer, ar_en_model, en_ar_tokenizer, en_ar_model):
    """Process medical image and question with enhanced Egyptian Arabic support"""
    try:
        # Detect question language
        detected_lang = detect_language(question)
        
        # Prepare questions in both languages
        if detected_lang == 'ar':
            question_ar = question.strip()
            question_en = translate_ar_to_en(question_ar, ar_en_tokenizer, ar_en_model)
        else:
            question_en = question.strip()
            question_ar = translate_en_to_ar(question_en, en_ar_tokenizer, en_ar_model)
        
        # Resize image to save memory
        image_resized = resize_image(image)
        
        # Process with BLIP model
        device = "cuda" if torch.cuda.is_available() else "cpu"
        inputs = processor(image_resized, question_en, return_tensors="pt")
        
        if torch.cuda.is_available():
            inputs = {k: v.to(device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=100,
                num_beams=3,
                early_stopping=True,
                do_sample=False
            )
        
        # Decode answer
        answer_en = processor.decode(outputs[0], skip_special_tokens=True).strip()
        
        # Enhanced Arabic translation
        answer_ar = translate_medical_response(answer_en, en_ar_tokenizer, en_ar_model)
        
        # Memory cleanup
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        
        return question_ar, question_en, answer_ar, answer_en
        
    except Exception as e:
        logger.exception("Medical query processing failed")
        error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"
        return error_msg, f"Processing error: {str(e)}", error_msg, f"Processing error: {str(e)}"

def get_memory_usage():
    """Get current memory usage"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # MB

def main():
    st.set_page_config(
        page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØµØ­Ø© Ø§Ù„Ù…ØµØ±ÙŠ - Egyptian Health Assistant",
        layout="wide",
        page_icon="ğŸ‡ªğŸ‡¬",
        initial_sidebar_state="expanded"
    )
    
    # Enhanced CSS with Egyptian theme
    st.markdown("""
    <style>
        .stApp {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        .main-header {
            background: linear-gradient(90deg, #c41e3a 0%, #ffffff 33%, #000000 66%, #c41e3a 100%);
            color: white;
            padding: 2rem;
            border-radius: 0 0 25px 25px;
            margin-bottom: 2rem;
            text-align: center;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        }
        .egypt-flag {
            font-size: 2rem;
            margin: 0 1rem;
        }
        .card {
            background: white;
            border-radius: 20px;
            padding: 2rem;
            box-shadow: 0 10px 40px rgba(0,0,0,0.1);
            margin-bottom: 2rem;
            border: 2px solid #f0f0f0;
        }
        .result-container {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 20px;
            padding: 2rem;
            margin: 2rem 0;
            color: white;
        }
        .arabic-text {
            font-family: 'Arial', 'Tahoma', sans-serif;
            font-size: 1.1rem;
            line-height: 1.8;
            direction: rtl;
            text-align: right;
        }
        .english-text {
            font-family: 'Segoe UI', sans-serif;
            font-size: 1.1rem;
            line-height: 1.6;
        }
        .stButton>button {
            background: linear-gradient(45deg, #c41e3a, #ff6b6b);
            color: white;
            border-radius: 15px;
            padding: 1rem 2rem;
            font-weight: 600;
            border: none;
            width: 100%;
            font-size: 1.1rem;
            transition: all 0.3s ease;
        }
        .stButton>button:hover {
            transform: translateY(-3px);
            box-shadow: 0 10px 25px rgba(196, 30, 58, 0.3);
        }
        .memory-info {
            font-size: 0.8rem;
            color: #666;
            text-align: center;
            margin-top: 1rem;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # Header with Egyptian theme
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ‡ªğŸ‡¬ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØµØ­Ø© Ø§Ù„Ù…ØµØ±ÙŠ ğŸ‡ªğŸ‡¬</h1>
        <h2>Egyptian Medical AI Assistant</h2>
        <p>Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ø·Ø¨ÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©</p>
        <p>AI-powered medical diagnosis in Egyptian Arabic</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Load models with progress indicator
    with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø·Ø¨ÙŠØ©... Loading medical AI models..."):
        try:
            processor, model, ar_en_tokenizer, ar_en_model, en_ar_tokenizer, en_ar_model = load_models()
            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­! Models loaded successfully!")
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {str(e)}")
            st.stop()
    
    # Main interface
    col1, col2 = st.columns([1, 1], gap="large")
    
    with col1:
        st.markdown("""
        <div class="card">
            <h3 style="text-align: center; margin-bottom: 1.5rem;">
                ğŸ“· Ø§Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·Ø¨ÙŠØ©<br>Upload Medical Image
            </h3>
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_file = st.file_uploader(
            "Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø·Ø¨ÙŠØ© / Choose medical image", 
            type=["jpg", "png", "jpeg", "bmp", "tiff"],
            help="Ø§Ø±ÙØ¹ Ø£Ø´Ø¹Ø© Ø£Ùˆ ØµÙˆØ± Ø·Ø¨ÙŠØ© Ù„Ù„ØªØ´Ø®ÙŠØµ / Upload X-rays or medical images for diagnosis"
        )
        
        if uploaded_file:
            try:
                image = Image.open(uploaded_file).convert("RGB")
                st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© / Uploaded Image", use_container_width=True)
                
                # Show image info
                st.info(f"ğŸ“ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø©: {image.size[0]}Ã—{image.size[1]} / Image size: {image.size[0]}Ã—{image.size[1]}")
                
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©: {str(e)} / Error opening image: {str(e)}")
    
    with col2:
        st.markdown("""
        <div class="card">
            <h3 style="text-align: center; margin-bottom: 1.5rem;">
                ğŸ’¬ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ø·Ø¨ÙŠ<br>Ask Your Medical Question
            </h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Language detection hint
        st.info("ğŸ’¡ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© / Write your question in Arabic or English")
        
        question = st.text_area(
            "Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ø·Ø¨ÙŠ / Your medical question:",
            placeholder="Ù…Ø«Ø§Ù„: Ø¥ÙŠÙ‡ Ø§Ù„Ù„ÙŠ Ø¨Ø§ÙŠÙ† ÙÙŠ Ø§Ù„Ø£Ø´Ø¹Ø© Ø¯ÙŠØŸ\nExample: What do you see in this X-ray?",
            height=120,
            help="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­ Ø¹Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·Ø¨ÙŠØ© / Write your question clearly about the medical image"
        )
        
        # Analyze button
        if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø·Ø¨ÙŠ / Medical Analysis", use_container_width=True):
            if not uploaded_file or not question.strip():
                st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ ØµÙˆØ±Ø© ÙˆÙƒØªØ§Ø¨Ø© Ø³Ø¤Ø§Ù„ / Please upload an image and enter a question")
            else:
                # Show processing status
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ø¨ÙŠ... Analyzing medical image..."):
                    try:
                        start_time = time.time()
                        
                        # Update progress
                        progress_bar.progress(25)
                        status_text.text("Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©... Processing image...")
                        
                        image_pil = Image.open(uploaded_file).convert("RGB")
                        
                        progress_bar.progress(50)
                        status_text.text("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„... Analyzing question...")
                        
                        # Process the query
                        q_ar, q_en, a_ar, a_en = process_medical_query(
                            image_pil, question, processor, model,
                            ar_en_tokenizer, ar_en_model, en_ar_tokenizer, en_ar_model
                        )
                        
                        progress_bar.progress(100)
                        status_text.text("ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„! Analysis complete!")
                        
                        processing_time = time.time() - start_time
                        
                        # Clear progress indicators
                        progress_bar.empty()
                        status_text.empty()
                        
                        # Display results
                        st.markdown("""
                        <div class="result-container">
                            <h2 style="text-align: center; margin-bottom: 2rem;">
                                ğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ø¨ÙŠ / Medical Analysis Results
                            </h2>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Results in two columns
                        res_col1, res_col2 = st.columns(2)
                        
                        with res_col1:
                            st.markdown("### ğŸ‡ªğŸ‡¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© / Arabic")
                            
                            st.markdown("**Ø§Ù„Ø³Ø¤Ø§Ù„:**")
                            st.markdown(f'<div class="arabic-text">{q_ar}</div>', unsafe_allow_html=True)
                            
                            st.markdown("**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**")
                            st.markdown(f'<div class="arabic-text" style="background: #e8f5e8; padding: 1rem; border-radius: 10px; color: #2d5a2d;">{a_ar}</div>', unsafe_allow_html=True)
                        
                        with res_col2:
                            st.markdown("### ğŸ‡ºğŸ‡¸ English")
                            
                            st.markdown("**Question:**")
                            st.markdown(f'<div class="english-text">{q_en}</div>', unsafe_allow_html=True)
                            
                            st.markdown("**Answer:**")
                            st.markdown(f'<div class="english-text" style="background: #e8f5e8; padding: 1rem; border-radius: 10px; color: #2d5a2d;">{a_en}</div>', unsafe_allow_html=True)
                        
                        # Processing info
                        memory_usage = get_memory_usage()
                        st.markdown(f"""
                        <div class="memory-info">
                            â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_time:.2f} Ø«Ø§Ù†ÙŠØ© / Processing time: {processing_time:.2f} seconds<br>
                            ğŸ’¾ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {memory_usage:.1f} MB / Memory usage: {memory_usage:.1f} MB
                        </div>
                        """, unsafe_allow_html=True)
                        
                    except Exception as e:
                        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)} / Processing error: {str(e)}")
    
    # Footer with medical disclaimer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; padding: 2rem; background: #f8f9fa; border-radius: 15px; margin-top: 2rem;">
        <h4>ğŸ¥ Ø¥Ø®Ù„Ø§Ø¡ Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© Ø·Ø¨ÙŠØ© / Medical Disclaimer</h4>
        <p><strong>Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ ÙŠÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£ÙˆÙ„ÙŠØ© ÙÙ‚Ø· ÙˆÙ„Ø§ ÙŠØ­Ù„ Ù…Ø­Ù„ Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ®ØµØµØ©</strong></p>
        <p><strong>This AI assistant provides preliminary information only and does not replace professional medical consultation</strong></p>
        <p>ğŸ”¬ Ù…Ø¯Ø¹ÙˆÙ… Ø¨ØªÙ‚Ù†ÙŠØ© BLIP Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø·Ø¨ÙŠ / Powered by BLIP Medical AI Technology</p>
        <p>ğŸ‡ªğŸ‡¬ ØµÙÙ…Ù… Ø®ØµÙŠØµØ§Ù‹ Ù„Ù„Ù…Ø¬ØªÙ…Ø¹ Ø§Ù„Ù…ØµØ±ÙŠ / Designed specifically for the Egyptian community</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
